整体来看，都是一个或多个卷积层跟一个pooling层，然后是全连接层，然后是softmax层。
pooling层通常采用最大池化，平均池化只在网络很深的情况可能会采用
卷积层要训的参数很少，有w和b要训练，池化层没有参数需要训练
从输入到输出的size会越来越小，但是信道数是不断增加的。
从输入到输出的activation size会逐渐减小，如果减小的过快会影响神经网络的性能，所以最后全连接层有几层
全连接层的参数最多，有w和b要训练